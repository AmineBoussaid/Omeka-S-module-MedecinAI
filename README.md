# ü©∫ MedecinAI ‚Äì Module Omeka S

Module Omeka S permettant de g√©n√©rer automatiquement des recommandations m√©dicales √† partir de transcriptions vocales, via une int√©gration directe avec **Ollama** (LLM local ou distant).

## üì¶ Installation

1. T√©l√©charger le module :

   * Depuis GitHub : [https://github.com/AmineBoussaid/Omeka-S-module-MedecinAI](https://github.com/AmineBoussaid/Omeka-S-module-MedecinAI)
   * Ou installer une Release versionn√©e si disponible.
2. D√©compresser l‚Äôarchive ZIP.
3. Renommer le dossier en **MedecinAI** *(important : le nom du dossier doit correspondre exactement au nom du module)*.
4. Copier le dossier dans :

   ```
   /modules/
   ```
5. Dans l‚Äôinterface admin Omeka S, aller dans :
   **Modules ‚Üí Installer MedecinAI**

## ‚öôÔ∏è Configuration

### Activer l‚Äôint√©gration Ollama

Active la g√©n√©ration automatique des recommandations √† partir de la transcription vocale.

### URL de l‚ÄôAPI Ollama

Par d√©faut :

```
http://localhost:11434/api/generate
```

Modifier cette URL si Ollama tourne sur un autre serveur :

```
http://ADRESSE_SERVEUR:11434/api/generate
```

### Mod√®le Ollama

Nom du mod√®le de langage utilis√©, par exemple :

* `gpt-oss:120b-cloud`
* `llama3.1`
* `mistral`
* `phi3`
  Le mod√®le doit √™tre install√© dans votre instance Ollama (`ollama list`).

### Langue de r√©ponse

Langue dans laquelle le mod√®le doit g√©n√©rer les recommandations.
Valeur recommand√©e : **Fran√ßais**

### Prompt syst√®me

Instruction transmise au mod√®le IA.
Utiliser `{transcription}` comme placeholder.

Prompt par d√©faut :

```
En tant que m√©decin, analysez les sympt√¥mes suivants et fournissez des recommandations m√©dicales : {transcription}
```

Prompt recommand√© (plus s√©curis√©) :

```
Tu es un assistant m√©dical. Analyse les sympt√¥mes suivants et fournis des recommandations g√©n√©rales √† vis√©e informative, sans √©tablir de diagnostic. Sympt√¥mes : {transcription}
```

### Temp√©rature (cr√©ativit√©)

Contr√¥le la cr√©ativit√© de la r√©ponse.

* 0.0 ‚Üí r√©ponse tr√®s pr√©visible
* 2.0 ‚Üí r√©ponse tr√®s cr√©ative

Valeur recommand√©e : 0.7
Pour √©viter les hallucinations m√©dicales : 0.5

### Nombre maximum de tokens

Longueur maximale de la r√©ponse g√©n√©r√©e.
Valeur recommand√©e : 500

## üìù Fonctionnement

1. Le module r√©cup√®re automatiquement la transcription vocale li√©e √† l‚Äôitem.
2. Il envoie la transcription √† Ollama via l‚ÄôAPI.
3. Le mod√®le g√©n√®re une recommandation m√©dicale personnalis√©e.
4. La recommandation est stock√©e ou affich√©e dans l‚Äôinterface Omeka S.

## üõ†Ô∏è D√©pendances

* Omeka S (version compatible selon `module.ini`)
* Ollama install√© en local ou sur un serveur distant ‚Üí [https://ollama.com](https://ollama.com)

## üë§ Auteur

**Amine Boussaid**
GitHub : [https://github.com/AmineBoussaid](https://github.com/AmineBoussaid)
